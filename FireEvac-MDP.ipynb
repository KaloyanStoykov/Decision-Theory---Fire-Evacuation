{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9647308d-61f7-4195-937c-2cff38810c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from envs.grid import Grid\n",
    "from envs.constants import SQUARE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13a716-a97c-4775-853d-ca2ab6f67bb5",
   "metadata": {},
   "source": [
    "# Fire Evacuation Planner MDP\n",
    "This agent will implement a classic MDP with states, rewards and transition models\n",
    "Extending the MDP to our use case could include:\n",
    " - Fire Spread algorithm:\n",
    "   - Episode ends if stepping in fire state\n",
    "   - Firefighter (MDP agent) recieves reward for steps that have people needing to rescue\n",
    "   - Generate an environment that includes more sophisticated properties - generate walls, based on grid, doors and so on...\n",
    "   - Default reward could be something like -0.04 to encourage efficiency\n",
    "   - Pass arguments to the grid when defining the base environment (walls, starting fire, people)\n",
    "\n",
    "## Compare Reinforcement Learning Methods (Q-learning, SARSA) to Classical Methods (Policy iteration, value iteration, linear programming)\n",
    "The separate models will aim to answer whether classical models or RL-based are better suited for a simulation of a real-world fire hazard on a building floor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990c01c-7f93-4805-a24e-f646b6b04227",
   "metadata": {},
   "source": [
    "# Possible challenges of a classical MDP implementation\n",
    "Since we are dealing with a classical-based MDP, we would need to make sure that all processes are markovian - taking action based only on current state and possible rewards.\n",
    "\n",
    "If we encode the fire in a way that it spreads independently, then that would mean that our agent acts in a non-MDP way.\n",
    "\n",
    " - One way to solve this would be to include the fire status of every grid, which can quickly turn out to be alot of calculations and statuses for a simple grid.\n",
    "\n",
    "For small grids in examples like 3x4 size, this would be a challenge but for bigger ones, Reinforcement Learning almost definitely need to be adopted in order to manage the changing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2335576-98d0-42fe-8ad2-e480e75a7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireEvacuationAgentMDP:\n",
    "    def __init__(self, start_state, grid: Grid):\n",
    "        self.grid = grid\n",
    "        self.rows = grid.size\n",
    "        self.cols = grid.size\n",
    "        self.actions = ['up', 'left', 'right', 'down']\n",
    "\n",
    "        self.possible_states = []\n",
    "        for y in range(self.rows):\n",
    "            for x in range(self.cols):\n",
    "                if self.grid.tiles[x][y].is_traversable:\n",
    "                    self.possible_states.append((x, y))\n",
    "\n",
    "        if start_state in self.possible_states:\n",
    "            self.start_state = self.current_state = start_state\n",
    "        else:\n",
    "            if self.possible_states:\n",
    "                self.start_state = self.current_state = self.possible_states[0]\n",
    "            else:\n",
    "                self.start_state = self.current_state = (0, 0) # Fallback, should ideally not happen if grid is valid\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state = self.start_state\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self, action):\n",
    "        if action not in self.actions:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        old_state = self.current_state\n",
    "        x, y = self.current_state\n",
    "        \n",
    "        new_state = None\n",
    "        match action:\n",
    "            case 'up':\n",
    "                new_state = (x, y + 1)\n",
    "            case 'left':\n",
    "                new_state = (x - 1, y)\n",
    "            case 'right':\n",
    "                new_state = (x + 1, y)\n",
    "            case 'down': # New action\n",
    "                new_state = (x, y - 1)\n",
    "        \n",
    "        if (0 <= new_state[0] < self.cols and\n",
    "            0 <= new_state[1] < self.rows and\n",
    "            self.grid.tiles[new_state[0]][new_state[1]].is_traversable): # Check traversability using the grid\n",
    "            self.current_state = new_state\n",
    "        else:\n",
    "            self.current_state = old_state  # stay in place if hitting wall or obstacle\n",
    "\n",
    "    def get_possible_states(self):\n",
    "        return self.possible_states\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Agent is at state {self.current_state}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba75e5f-ef43-4241-a0c7-32f9f8b8c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_instance = Grid(size = 5, tile_size=SQUARE_SIZE)\n",
    "initial_agent_pos = (0,0)\n",
    "found_traversable = False\n",
    "for y in range(grid_instance.size):\n",
    "    for x in range(grid_instance.size):\n",
    "        if grid_instance.tiles[x][y].is_traversable:\n",
    "            actual_start_state = (x, y)\n",
    "            found_traversable = True\n",
    "            break\n",
    "    if found_traversable:\n",
    "        break\n",
    "\n",
    "\n",
    "if not found_traversable:\n",
    "    print(\"Warning: No traversable states found in the grid!\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c9c32ad-197e-4ddf-aea9-d36d56f48179",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = FireEvacuationAgentMDP(start_state=actual_start_state, grid=grid_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed7f005-2c2b-4bb7-82f5-bea8579cd44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is at state (0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d08616c-5540-4677-a2ec-834b424404c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is at state (1, 0)\n",
      "Agent is at state (1, 0)\n",
      "Agent is at state (0, 0)\n",
      "Agent is at state (0, 1)\n"
     ]
    }
   ],
   "source": [
    "# Test moves\n",
    "mdp.step('right')\n",
    "print(mdp)\n",
    "mdp.step('down')\n",
    "print(mdp)\n",
    "mdp.step('left')\n",
    "print(mdp)\n",
    "mdp.step('up')\n",
    "print(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd045a16-fa0d-4197-bccc-6ca97047441b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
